{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar-10-MLP",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyM2hyoxIEO4sAhZEftC5/Un",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ingenium70/happyDL/blob/master/Cifar_10_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERmSQ0oW9Xaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q torch torchvision\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVoNnvCc-lks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "import time\n",
        "#from mpl_toolkits import mplot3d\n",
        "\n",
        "from mpl_toolkits.mplot3d import axes3d\n",
        "from matplotlib import cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dock_CH2b7j",
        "colab_type": "text"
      },
      "source": [
        "#Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_DO5FM3-6QT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "partition ={'train': trainset, 'val': valset, 'test': testset}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDMsg17F2Rei",
        "colab_type": "text"
      },
      "source": [
        "#Data check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uPyiSrb_l7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# functions to show an image\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('     %5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxLxLH682qAW",
        "colab_type": "text"
      },
      "source": [
        "#Model Architecture "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H24xgUsAB9TZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, hid_dim, n_layer, act, dropout, use_bn, use_xavier):\n",
        "        super(MLP, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layer = n_layer\n",
        "        self.act = act\n",
        "        self.dropout = dropout\n",
        "        self.use_bn = use_bn\n",
        "        self.use_xavier = use_xavier\n",
        "    \n",
        "        self.fc1 = nn.Linear(self.in_dim, self.hid_dim)\n",
        "        self.linears = nn.ModuleList()\n",
        "        self.bns = nn.ModuleList()\n",
        "\n",
        "        for i in range(self.n_layer-1):\n",
        "            self.linears.append(nn.Linear(self.hid_dim, self.hid_dim))  \n",
        "            if self.use_bn:\n",
        "                self.bns.append(nn.BatchNorm1d(self.hid_dim))\n",
        "\n",
        "        self.fc2 = nn.Linear(self.hid_dim, self.out_dim)\n",
        "\n",
        "        if self.act == 'relu':\n",
        "            self.act = nn.ReLU()\n",
        "        elif self.act == 'tanh':\n",
        "            self.act = nn.Tanh()\n",
        "        elif self.act == 'sigmoid':\n",
        "            self.act = nn.Sigmoid()\n",
        "        else:\n",
        "            raise ValueError('no valid activation function selected!')\n",
        "\n",
        "        self.dropout = nn.Dropout(self.dropout)\n",
        "        if self.use_xavier:\n",
        "            self.xavier_init()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.act(self.fc1(x))\n",
        "        for i in range(len(self.linears)):\n",
        "            x = self.act(self.linears[i](x))\n",
        "            x = self.bns[i](x)\n",
        "            x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def xavier_init(self):\n",
        "        for linear in self.linears:\n",
        "            nn.init.xavier_normal_(linear.weight)\n",
        "            linear.bias.data.fill_(0.01)\n",
        "\n",
        "net = MLP(3072, 10, 100, 4, 'relu', 0.1, True, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVBxG5soTSG7",
        "colab_type": "text"
      },
      "source": [
        "# Train, Validate, Test and Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlmFCNh0TMru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#=========== Train ==============#\n",
        "\n",
        "def train(net, partition, optimizer, criterion, args):\n",
        "    trainloader = torch.utils.data.DataLoader(partition['train'], batch_size=args.train_batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    net.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    running_loss = 0.0\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.view(-1, 3072)\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total +=labels.size(0)\n",
        "        correct +=(predicted == labels).sum().item()\n",
        "    \n",
        "    train_loss = train_loss / len(trainloader)\n",
        "    train_acc = 100 * correct / total\n",
        "    \n",
        "    return net, train_loss, train_acc\n",
        "\n",
        "#=========== Validate ==============#\n",
        "\n",
        "def validate(net, partition, criterion, args):\n",
        "    valloader = torch.utils.data.DataLoader(partition['val'], batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            images, labels = data\n",
        "            images = images.view(-1, 3072)\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            outputs = net.forward(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss +=loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss/len(valloader)\n",
        "        val_acc = 100*correct /total\n",
        "    return val_loss, val_acc\n",
        "\n",
        "#=========== Test ==============#\n",
        "\n",
        "def test(net, partition, args):\n",
        "    testloader = torch.utils.data.DataLoader(partition['test'], batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    net.eval()\n",
        "   \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images = images.view(-1, 3072)\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            outputs = net.forward(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        test_acc = 100*correct/total\n",
        "\n",
        "    return test_acc\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVBcToU73mxx",
        "colab_type": "text"
      },
      "source": [
        "#Experiement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGW-jqWy3wLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def experiment(partition, args):\n",
        "    net = MLP(args.in_dim, args.out_dim, args.hid_dim, args.n_layer, args.act, args.dropout,\n",
        "              args.use_bn, args.use_xavier)\n",
        "    net.cuda()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if args.optim == 'SGD':\n",
        "        optimizer = optim.SGD(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'RMSprop':\n",
        "        optimizer = optim.RMSprop(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'Adam':\n",
        "        optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    else:\n",
        "        raise ValueError('no valid optimizer choice!')\n",
        "\n",
        "    for epoch in range(args.ep):  # loop over the dataset multiple times\n",
        "        ts = time.time()\n",
        "        net, train_loss, train_acc = train(net, partition, optimizer, criterion, args)\n",
        "        val_loss, val_acc = validate(net, partition, criterion, args)\n",
        "        te = time.time()\n",
        "        print('Epoch{}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.2f}/{:2.2f}. Took {: 2.2f} sec'\n",
        "                .format(epoch, train_acc, val_acc, train_loss, val_loss, te-ts))\n",
        "    \n",
        "    test_acc = test(net, partition, args)\n",
        "\n",
        "    return train_loss, val_loss, train_acc, val_acc, test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g13GlI98y8lg",
        "colab_type": "text"
      },
      "source": [
        "#Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "83QUk6oPA202",
        "colab": {}
      },
      "source": [
        "#=============Random Seed Initialization =================#\n",
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "args = parser.parse_args(\"\")\n",
        "\n",
        "#===============Model Capacity ==================#\n",
        "args.in_dim = 3072\n",
        "args.out_dim = 10\n",
        "args.hid_dim = 100\n",
        "args.act = 'relu'\n",
        "\n",
        "#============Regularization ==================#\n",
        "args.dropout = 0.2\n",
        "args.use_bn = True\n",
        "args.l2 = 0.00001\n",
        "args.use_xavier = True\n",
        "\n",
        "#=================Optimizer & Training ==========#\n",
        "args.optim = 'RMSprop'\n",
        "args.lr = 0.0015\n",
        "args.ep = 10\n",
        "\n",
        "args.train_batch_size = 256\n",
        "args.test_batch_size = 1024\n",
        "\n",
        "#=================Experiment Variables =============#\n",
        "name_var1 = 'n_layer'\n",
        "name_var2 = 'hid_dim'\n",
        "\n",
        "list_var1 = [3,5,6]\n",
        "list_var2 = [500, 300, 700]\n",
        "\n",
        "for var1 in list_var1:\n",
        "    for var2 in list_var2:\n",
        "        setattr(args, name_var1, var1)\n",
        "        setattr(args, name_var2, var2)\n",
        "        print(args)\n",
        "        result = experiment(partition, args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx40B6V3y0BL",
        "colab_type": "text"
      },
      "source": [
        "#Reprot Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ5ZPeS7yxq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(15,5))\n",
        "list_val_acc = np.reshape(list_val_acc, (3, 3))\n",
        "\n",
        "# ====== Validation accuracy Fluctuation ====== #\n",
        "ax1 = fig.add_subplot(1, 2, 1, projection= '3d')\n",
        "ax1.contour(list_var1, list_var2, list_val_acc, 50, cmap='binary')\n",
        "ax1.set_xlabel('n_layer')\n",
        "ax1.set_ylabel('hid_dim')\n",
        "ax1.set_zlabel('val_acc')\n",
        "\n",
        "\"\"\"\n",
        "ax1.plot(list_epoch, list_train_loss, label='train_loss')\n",
        "ax1.plot(list_epoch, list_val_loss, '--', label='val_loss')\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.set_ylabel('loss')\n",
        "ax1.grid()\n",
        "ax1.legend()\n",
        "ax1.set_title('epoch vs loss')\n",
        "\n",
        "\n",
        "# ====== Metric Fluctuation ====== #\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax2.plot(list_acc_epoch, list_acc, marker='x', label='Accuracy metric')\n",
        "ax2.set_xlabel('epoch')\n",
        "ax2.set_ylabel('Acc')\n",
        "ax2.grid()\n",
        "ax2.legend()\n",
        "ax2.set_title('epoch vs Accuracy')\n",
        "\"\"\"\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}